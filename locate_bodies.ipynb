{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.5\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from person_features import PersonFeatures\n",
    "from global_features import GlobalFeatures\n",
    "from fusion_module import FusionModule\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from pygame import mixer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import cv2\n",
    "\n",
    "\n",
    "test_image = 'EMOTIC/emotic/mscoco/images/COCO_train2014_000000084211.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 5 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Extended face detection example to body detection for neural net analysis \n",
    "# functinoality from examples/find_faces_in_picture.py in face_recognition repositiory\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(test_image)\n",
    "im = Image.open(test_image)\n",
    "im.show()\n",
    "# Find all the faces in the image using the default HOG-based model.\n",
    "# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n",
    "# See also: find_faces_in_picture_cnn.py\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A body is located at pixel location Top: 55, Left: 93, Bottom: 322, Right: 171\n",
      "A body is located at pixel location Top: 93, Left: 414, Bottom: 318, Right: 477\n",
      "A body is located at pixel location Top: 109, Left: 288, Bottom: 298, Right: 342\n",
      "A body is located at pixel location Top: 78, Left: 502, Bottom: 345, Right: 580\n",
      "A body is located at pixel location Top: 103, Left: 197, Bottom: 328, Right: 263\n"
     ]
    }
   ],
   "source": [
    "# take in an image and a face location \n",
    "# extend to locate body bbox \n",
    "def within_boundaries(image, loc): \n",
    "    h,w,d = image.shape    \n",
    "    t,r,b,l = loc \n",
    "    # cropped h, w \n",
    "    ch = abs(t-b)\n",
    "    cw = abs(l-r)\n",
    "    scale = 4 \n",
    "    temp = scale - 0.5\n",
    "\n",
    "    # set new scaled body box estimate\n",
    "    l = l - int(cw/scale) \n",
    "    r = r + int(cw/scale)\n",
    "\n",
    "    b = b + scale*ch\n",
    "    t = t - int(ch/scale)\n",
    "    \n",
    "    # ensure within proper boundaries\n",
    "    while l < 0: \n",
    "        l = l - int(cw/temp) \n",
    "        temp -=0.5\n",
    "\n",
    "    while r > w: \n",
    "        r = r + int(cw/temp) \n",
    "        temp -=0.5\n",
    "        \n",
    "    while b > h: \n",
    "        b = b + temp*ch\n",
    "        temp -=0.5\n",
    "        \n",
    "    while t < 0: \n",
    "        t = t - int(ch/temp)\n",
    "        temp -=0.5\n",
    "    \n",
    "    return t,r,b,l\n",
    "\n",
    "for i,loc in enumerate(face_locations):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = loc\n",
    "    # extend to full body detection \n",
    "#     face_image = image[top:bottom, left:right]\n",
    "#     pil_image = Image.fromarray(face_image)\n",
    "#     pil_image.show()\n",
    "\n",
    "    t,r,b,l = within_boundaries(image, loc)\n",
    "    print(\"A body is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(t,l,b,r))\n",
    "    body = image[t:b,l:r]\n",
    "\n",
    "    pil_image = Image.fromarray(body)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
